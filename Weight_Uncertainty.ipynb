{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Weight_Uncertainty.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alisa-Liang/colab/blob/main/Weight_Uncertainty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1pmLXqsSREL",
        "outputId": "864022ed-00d0-41db-ad10-5ad6d6fec1a3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eItMAsYfTc-T",
        "outputId": "79871522-839b-46d5-c6b4-22d1ece6a0d1"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubt1iJ5sSphD"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm, trange\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:21.331568Z",
          "iopub.execute_input": "2021-10-28T09:50:21.331951Z",
          "iopub.status.idle": "2021-10-28T09:50:24.772042Z",
          "shell.execute_reply.started": "2021-10-28T09:50:21.331860Z",
          "shell.execute_reply": "2021-10-28T09:50:24.770793Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-DmLxKySNwR",
        "outputId": "dabf3409-5e4c-473a-e0c0-ad68cb3bda27"
      },
      "source": [
        "\n",
        "\n",
        "writer = SummaryWriter()\n",
        "sns.set()\n",
        "sns.set_style(\"dark\")\n",
        "sns.set_palette(\"muted\")\n",
        "sns.set_color_codes(\"muted\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T10:01:39.174412Z",
          "iopub.execute_input": "2021-10-28T10:01:39.174685Z",
          "iopub.status.idle": "2021-10-28T10:01:39.280898Z",
          "shell.execute_reply.started": "2021-10-28T10:01:39.174655Z",
          "shell.execute_reply": "2021-10-28T10:01:39.279731Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CPSP7UiSNwX",
        "outputId": "722c1541-86c6-46a4-914b-89dd5045292a"
      },
      "source": [
        "normalize=transforms.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5])\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(28*28),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(), \n",
        "    normalize\n",
        "])\n",
        "\n",
        "train_loader=ImageFolder('/content/drive/MyDrive/Colab Notebooks/Kather_Weight_Uncertainty/train',transform=transform)\n",
        "test_loader=ImageFolder('/content/drive/MyDrive/Colab Notebooks/Kather_Weight_Uncertainty/val',transform=transform)\n",
        "target = train_loader.class_to_idx\n",
        "print(train_loader[0][0].size())\n",
        "print(normalize)\n",
        "print(train_loader[0][1])\n",
        "print(train_loader[0][0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784, 784])\n",
            "Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "0\n",
            "tensor([[[-0.3490, -0.3490, -0.3490,  ..., -0.4745, -0.4745, -0.4745],\n",
            "         [-0.3490, -0.3490, -0.3490,  ..., -0.4745, -0.4745, -0.4745],\n",
            "         [-0.3490, -0.3490, -0.3490,  ..., -0.4745, -0.4745, -0.4745],\n",
            "         ...,\n",
            "         [-0.5451, -0.5451, -0.5451,  ..., -0.2392, -0.2392, -0.2392],\n",
            "         [-0.5451, -0.5451, -0.5451,  ..., -0.2392, -0.2392, -0.2392],\n",
            "         [-0.5451, -0.5451, -0.5451,  ..., -0.2392, -0.2392, -0.2392]],\n",
            "\n",
            "        [[-0.7176, -0.7176, -0.7176,  ..., -0.8275, -0.8275, -0.8275],\n",
            "         [-0.7176, -0.7176, -0.7176,  ..., -0.8275, -0.8275, -0.8275],\n",
            "         [-0.7176, -0.7176, -0.7176,  ..., -0.8275, -0.8275, -0.8275],\n",
            "         ...,\n",
            "         [-0.8588, -0.8588, -0.8588,  ..., -0.6549, -0.6549, -0.6549],\n",
            "         [-0.8588, -0.8588, -0.8588,  ..., -0.6549, -0.6549, -0.6549],\n",
            "         [-0.8588, -0.8588, -0.8588,  ..., -0.6549, -0.6549, -0.6549]],\n",
            "\n",
            "        [[-0.3569, -0.3569, -0.3569,  ..., -0.5059, -0.5059, -0.5059],\n",
            "         [-0.3569, -0.3569, -0.3569,  ..., -0.5059, -0.5059, -0.5059],\n",
            "         [-0.3569, -0.3569, -0.3569,  ..., -0.5059, -0.5059, -0.5059],\n",
            "         ...,\n",
            "         [-0.5686, -0.5686, -0.5686,  ..., -0.2941, -0.2941, -0.2941],\n",
            "         [-0.5686, -0.5686, -0.5686,  ..., -0.2941, -0.2941, -0.2941],\n",
            "         [-0.5686, -0.5686, -0.5686,  ..., -0.2941, -0.2941, -0.2941]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:25.286951Z",
          "iopub.execute_input": "2021-10-28T09:50:25.287547Z",
          "iopub.status.idle": "2021-10-28T09:50:25.296079Z",
          "shell.execute_reply.started": "2021-10-28T09:50:25.287487Z",
          "shell.execute_reply": "2021-10-28T09:50:25.294873Z"
        },
        "trusted": true,
        "id": "Q86MyEsDSNwY"
      },
      "source": [
        "#Data Preparation\n",
        "BATCH_SIZE = 10\n",
        "TEST_BATCH_SIZE = 5\n",
        "\n",
        "TRAIN_SIZE = 500\n",
        "TEST_SIZE = 10\n",
        "NUM_BATCHES = len(train_loader)\n",
        "NUM_TEST_BATCHES = len(test_loader)\n",
        "\n",
        "CLASSES = 8\n",
        "TRAIN_EPOCHS = 10\n",
        "SAMPLES = 2\n",
        "TEST_SAMPLES = 8\n",
        "\n",
        "assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
        "assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:25.299452Z",
          "iopub.execute_input": "2021-10-28T09:50:25.300150Z",
          "iopub.status.idle": "2021-10-28T09:50:25.311333Z",
          "shell.execute_reply.started": "2021-10-28T09:50:25.300103Z",
          "shell.execute_reply": "2021-10-28T09:50:25.310167Z"
        },
        "trusted": true,
        "id": "9gr_TMnhSNwZ"
      },
      "source": [
        "class Gaussian(object):\n",
        "    def __init__(self, mu, rho):\n",
        "        super().__init__()\n",
        "        self.mu = mu\n",
        "        self.rho = rho\n",
        "        self.normal = torch.distributions.Normal(0,1)\n",
        "    \n",
        "    @property\n",
        "    def sigma(self):\n",
        "        return torch.log1p(torch.exp(self.rho))\n",
        "    \n",
        "    def sample(self):\n",
        "        epsilon = self.normal.sample(self.rho.size()).to(DEVICE)\n",
        "        return self.mu + self.sigma * epsilon\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        return (-math.log(math.sqrt(2 * math.pi))\n",
        "                - torch.log(self.sigma)\n",
        "                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:25.313157Z",
          "iopub.execute_input": "2021-10-28T09:50:25.313814Z",
          "iopub.status.idle": "2021-10-28T09:50:25.326516Z",
          "shell.execute_reply.started": "2021-10-28T09:50:25.313766Z",
          "shell.execute_reply": "2021-10-28T09:50:25.325317Z"
        },
        "trusted": true,
        "id": "CA1VBribSNwa"
      },
      "source": [
        "class ScaleMixtureGaussian(object):\n",
        "    def __init__(self, pi, sigma1, sigma2):\n",
        "        super().__init__()\n",
        "        self.pi = pi\n",
        "        self.sigma1 = sigma1\n",
        "        self.sigma2 = sigma2\n",
        "        self.gaussian1 = torch.distributions.Normal(0,sigma1)\n",
        "        self.gaussian2 = torch.distributions.Normal(0,sigma2)\n",
        "    \n",
        "    def log_prob(self, input):\n",
        "        prob1 = torch.exp(self.gaussian1.log_prob(input))\n",
        "        prob2 = torch.exp(self.gaussian2.log_prob(input))\n",
        "        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:25.328391Z",
          "iopub.execute_input": "2021-10-28T09:50:25.328973Z",
          "iopub.status.idle": "2021-10-28T09:50:29.228697Z",
          "shell.execute_reply.started": "2021-10-28T09:50:25.328926Z",
          "shell.execute_reply": "2021-10-28T09:50:29.226598Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "pikqCe-vSNwb",
        "outputId": "29dc5552-e94f-4b96-d290-4d8f3e94c8c5"
      },
      "source": [
        "PI = 0.5\n",
        "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
        "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
        "\n",
        "def visualize_scale_mixture_components():\n",
        "    def show_lines():\n",
        "        pass\n",
        "    mix = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "    normal_1 = torch.distributions.Normal(0, SIGMA_1)\n",
        "    normal_2 = torch.distributions.Normal(0, SIGMA_2)\n",
        "    x_points = np.linspace(-5,5,10000)\n",
        "    d1 = np.array([torch.exp(normal_1.log_prob(float(c))) for c in x_points])\n",
        "    d2 = np.array([torch.exp(normal_2.log_prob(float(c))) for c in x_points])\n",
        "    d3 = np.array([torch.exp(mix.log_prob(float(c))) for c in x_points])\n",
        "    plt.subplots(1,3,figsize=(14,4))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
        "    plt.ylim(0,0.5)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.legend([\"sigma1\", \"sigma2\", \"mix\"])\n",
        "    plt.ylim(0,160)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(x_points,d2,color=\"g\")\n",
        "    plt.plot(x_points,d3,color=\"r\")\n",
        "    plt.plot(x_points,d1,color=\"b\")\n",
        "    plt.legend([\"sigma2\", \"mix\", \"sigma1\"])\n",
        "    plt.ylim(0,80)\n",
        "    \n",
        "visualize_scale_mixture_components()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f2c769099d40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mvisualize_scale_mixture_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-f2c769099d40>\u001b[0m in \u001b[0;36mvisualize_scale_mixture_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnormal_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIGMA_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f2c769099d40>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnormal_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIGMA_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_points\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# compute the variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The value argument to log_prob must be a Tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mevent_dim_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The value argument to log_prob must be a Tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:41.244294Z",
          "iopub.execute_input": "2021-10-28T09:50:41.244562Z",
          "iopub.status.idle": "2021-10-28T09:50:41.256895Z",
          "shell.execute_reply.started": "2021-10-28T09:50:41.244530Z",
          "shell.execute_reply": "2021-10-28T09:50:41.255737Z"
        },
        "trusted": true,
        "id": "JF7jSlM8SNwc"
      },
      "source": [
        "class BayesianLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # Weight parameters\n",
        "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))\n",
        "        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))\n",
        "        self.weight = Gaussian(self.weight_mu, self.weight_rho)\n",
        "        # Bias parameters\n",
        "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
        "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
        "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
        "        # Prior distributions\n",
        "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
        "        self.log_prior = 0\n",
        "        self.log_variational_posterior = 0\n",
        "\n",
        "    def forward(self, input, sample=False, calculate_log_probs=False):\n",
        "        if self.training or sample:\n",
        "            weight = self.weight.sample()\n",
        "            bias = self.bias.sample()\n",
        "        else:\n",
        "            weight = self.weight.mu\n",
        "            bias = self.bias.mu\n",
        "        if self.training or calculate_log_probs:\n",
        "            self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)\n",
        "            self.log_variational_posterior = self.weight.log_prob(weight) + self.bias.log_prob(bias)\n",
        "        else:\n",
        "            self.log_prior, self.log_variational_posterior = 0, 0\n",
        "\n",
        "        return F.linear(input, weight, bias)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:43.723742Z",
          "iopub.execute_input": "2021-10-28T09:50:43.724056Z",
          "iopub.status.idle": "2021-10-28T09:50:43.789463Z",
          "shell.execute_reply.started": "2021-10-28T09:50:43.724009Z",
          "shell.execute_reply": "2021-10-28T09:50:43.788522Z"
        },
        "trusted": true,
        "id": "Z-rZrRP3SNwd"
      },
      "source": [
        "class BayesianNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = BayesianLinear(28*28, 400)\n",
        "        self.l2 = BayesianLinear(400, 400)\n",
        "        self.l3 = BayesianLinear(400, 10)\n",
        "    \n",
        "    def forward(self, x, sample=False):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.l1(x, sample))\n",
        "        x = F.relu(self.l2(x, sample))\n",
        "        x = F.log_softmax(self.l3(x, sample), dim=1)\n",
        "        return x\n",
        "    \n",
        "    def log_prior(self):\n",
        "        return self.l1.log_prior \\\n",
        "               + self.l2.log_prior \\\n",
        "               + self.l3.log_prior\n",
        "    \n",
        "    def log_variational_posterior(self):\n",
        "        return self.l1.log_variational_posterior \\\n",
        "               + self.l2.log_variational_posterior \\\n",
        "               + self.l3.log_variational_posterior\n",
        "    \n",
        "    def sample_elbo(self, input, target, samples=SAMPLES):\n",
        "        outputs = torch.zeros(samples, BATCH_SIZE, CLASSES).to(DEVICE)\n",
        "        log_priors = torch.zeros(samples).to(DEVICE)\n",
        "        log_variational_posteriors = torch.zeros(samples).to(DEVICE)\n",
        "        for i in range(samples):\n",
        "            outputs[i] = self(input, sample=True)\n",
        "            log_priors[i] = self.log_prior()\n",
        "            log_variational_posteriors[i] = self.log_variational_posterior()\n",
        "        log_prior = log_priors.mean()\n",
        "        log_variational_posterior = log_variational_posteriors.mean()\n",
        "        negative_log_likelihood = F.nll_loss(outputs.mean(0), target, size_average=False)\n",
        "        loss = (log_variational_posterior - log_prior)/NUM_BATCHES + negative_log_likelihood\n",
        "        return loss, log_prior, log_variational_posterior, negative_log_likelihood\n",
        "\n",
        "net = BayesianNetwork().to(DEVICE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:46.280364Z",
          "iopub.execute_input": "2021-10-28T09:50:46.280817Z",
          "iopub.status.idle": "2021-10-28T09:50:46.292253Z",
          "shell.execute_reply.started": "2021-10-28T09:50:46.280747Z",
          "shell.execute_reply": "2021-10-28T09:50:46.291275Z"
        },
        "trusted": true,
        "id": "I-LjqqM9SNwe"
      },
      "source": [
        "def write_weight_histograms(epoch):\n",
        "    writer.add_histogram('histogram/w1_mu', net.l1.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w1_rho', net.l1.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/w2_mu', net.l2.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w2_rho', net.l2.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/w3_mu', net.l3.weight_mu,epoch)\n",
        "    writer.add_histogram('histogram/w3_rho', net.l3.weight_rho,epoch)\n",
        "    writer.add_histogram('histogram/b1_mu', net.l1.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b1_rho', net.l1.bias_rho,epoch)\n",
        "    writer.add_histogram('histogram/b2_mu', net.l2.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b2_rho', net.l2.bias_rho,epoch)\n",
        "    writer.add_histogram('histogram/b3_mu', net.l3.bias_mu,epoch)\n",
        "    writer.add_histogram('histogram/b3_rho', net.l3.bias_rho,epoch)\n",
        "\n",
        "def write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood):\n",
        "    writer.add_scalar('logs/loss', loss, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/complexity_cost', log_variational_posterior-log_prior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/log_prior', log_prior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/log_variational_posterior', log_variational_posterior, epoch*NUM_BATCHES+batch_idx)\n",
        "    writer.add_scalar('logs/negative_log_likelihood', negative_log_likelihood, epoch*NUM_BATCHES+batch_idx)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:49.090590Z",
          "iopub.execute_input": "2021-10-28T09:50:49.091279Z",
          "iopub.status.idle": "2021-10-28T09:50:49.098786Z",
          "shell.execute_reply.started": "2021-10-28T09:50:49.091241Z",
          "shell.execute_reply": "2021-10-28T09:50:49.097387Z"
        },
        "trusted": true,
        "id": "pLeAIU62SNwg"
      },
      "source": [
        "def train(net, optimizer, epoch):\n",
        "    net.train()\n",
        "    if epoch == 0: # write initial distributions\n",
        "        write_weight_histograms(epoch)\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
        "        data = data.to(DEVICE)\n",
        "        net.zero_grad()\n",
        "        loss, log_prior, log_variational_posterior, negative_log_likelihood = net.sample_elbo(data, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        write_loss_scalars(epoch, batch_idx, loss, log_prior, log_variational_posterior, negative_log_likelihood)\n",
        "    write_weight_histograms(epoch+1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:50.921617Z",
          "iopub.execute_input": "2021-10-28T09:50:50.922432Z",
          "iopub.status.idle": "2021-10-28T09:50:52.387172Z",
          "shell.execute_reply.started": "2021-10-28T09:50:50.922395Z",
          "shell.execute_reply": "2021-10-28T09:50:52.385781Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "_GOM6HWMSNwg",
        "outputId": "bb822b7e-9d0d-4027-c1e4-5dcf41ce8cb8"
      },
      "source": [
        "optimizer = optim.Adam(net.parameters())\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    train(net, optimizer, epoch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/4010 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cec21c699ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ebe564aa401d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_variational_posterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_elbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4e606d7fa5f4>\u001b[0m in \u001b[0;36msample_elbo\u001b[0;34m(self, input, target, samples)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlog_variational_posteriors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mlog_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mlog_variational_posteriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_variational_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (8) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [10, 8].  Tensor sizes: [2352, 10]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:29.246635Z",
          "iopub.status.idle": "2021-10-28T09:50:29.247273Z",
          "shell.execute_reply.started": "2021-10-28T09:50:29.246939Z",
          "shell.execute_reply": "2021-10-28T09:50:29.246972Z"
        },
        "trusted": true,
        "id": "dfk-0GbESNwh"
      },
      "source": [
        "def test_ensemble():\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    corrects = np.zeros(TEST_SAMPLES+1, dtype=int)\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            outputs = torch.zeros(TEST_SAMPLES+1, TEST_BATCH_SIZE, CLASSES).to(DEVICE)\n",
        "            for i in range(TEST_SAMPLES):\n",
        "                outputs[i] = net(data, sample=True)\n",
        "            outputs[TEST_SAMPLES] = net(data, sample=False)\n",
        "            output = outputs.mean(0)\n",
        "            preds = preds = outputs.max(2, keepdim=True)[1]\n",
        "            pred = output.max(1, keepdim=True)[1] # index of max log-probability\n",
        "            corrects += preds.eq(target.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    for index, num in enumerate(corrects):\n",
        "        if index < TEST_SAMPLES:\n",
        "            print('Component {} Accuracy: {}/{}'.format(index, num, TEST_SIZE))\n",
        "        else:\n",
        "            print('Posterior Mean Accuracy: {}/{}'.format(num, TEST_SIZE))\n",
        "    print('Ensemble Accuracy: {}/{}'.format(correct, TEST_SIZE))\n",
        "\n",
        "test_ensemble()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-28T09:50:29.249438Z",
          "iopub.status.idle": "2021-10-28T09:50:29.250050Z",
          "shell.execute_reply.started": "2021-10-28T09:50:29.249741Z",
          "shell.execute_reply": "2021-10-28T09:50:29.249775Z"
        },
        "trusted": true,
        "id": "9N5RlJILSNwh"
      },
      "source": [
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}